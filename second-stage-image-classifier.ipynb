{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10772323,"sourceType":"datasetVersion","datasetId":6682996}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### FLOOD PROBABILITY PREDICTION\n* The goal of this notebook is to use computer vision on the static images to predict the probability of a location having a flood or not\n* This probability will then be used as a feature for subsequent models and also used in normalizing the predictions to prevent overconfident predictions that hurt the loglosss score ","metadata":{}},{"cell_type":"code","source":"!pip install albumentations -q\n!pip install timm -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:25.594002Z","iopub.execute_input":"2025-02-17T10:09:25.594517Z","iopub.status.idle":"2025-02-17T10:09:43.727644Z","shell.execute_reply.started":"2025-02-17T10:09:25.594420Z","shell.execute_reply":"2025-02-17T10:09:43.726397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\nimport random\nimport albumentations\nfrom albumentations.pytorch import ToTensorV2\nimport pandas as pd\nimport numpy as np\nimport gc \nimport timm\nfrom fastai.vision.all import *\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom fastai.metrics import accuracy\n\nle = LabelEncoder()\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:43.729991Z","iopub.execute_input":"2025-02-17T10:09:43.730412Z","iopub.status.idle":"2025-02-17T10:09:51.226999Z","shell.execute_reply.started":"2025-02-17T10:09:43.730370Z","shell.execute_reply":"2025-02-17T10:09:51.226089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def random_seed(seed_value, use_cuda): \n    np.random.seed(seed_value)\n #cpu vars\n    torch.manual_seed(seed_value) \n# cpu  vars\n    random.seed(seed_value)\n # Python \n    if use_cuda: \n        torch.cuda.manual_seed(seed_value) \n        torch.cuda.manual_seed_all(seed_value) \n# gpu vars\n        torch.backends.cudnn.deterministic = True \n #needed\n        torch.backends.cudnn.benchmark = False \n#Remember to use num_workers=0 when creating the DataBunch.\n\nrandom_seed(2024,True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:51.228205Z","iopub.execute_input":"2025-02-17T10:09:51.228771Z","iopub.status.idle":"2025-02-17T10:09:51.239847Z","shell.execute_reply.started":"2025-02-17T10:09:51.228730Z","shell.execute_reply":"2025-02-17T10:09:51.238962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = \"/kaggle/input/final-deepmind-comp-dataset/final_deepmind_comp_dataset/zindi_data/\"\ntrain = pd.read_csv(path + \"Train.csv\")\ntest = pd.read_csv(path + \"Test.csv\")\nimages = np.load(path + \"composite_images.npz\")\ndef get_location(value):\n  return value.split(\"_\")[0] + '_' + value.split(\"_\")[1]\n\ndef get_event_id(value):\n  return value.split(\"_\")[3]\nfor df in [train, test]:\n  df['location_id'] = df['event_id'].apply(lambda x: get_location(x))\n  df['event'] = df['event_id'].apply(lambda x: get_event_id(x))\n\nprint(len(set(train['location_id'])), len(set(test['location_id'])))\nprint(len(set(train['location_id']).intersection(set(test['location_id']))))\nprint(len(images))\ndisplay(train.head(), test.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:51.242046Z","iopub.execute_input":"2025-02-17T10:09:51.242403Z","iopub.status.idle":"2025-02-17T10:09:52.712191Z","shell.execute_reply.started":"2025-02-17T10:09:51.242366Z","shell.execute_reply":"2025-02-17T10:09:52.711247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_grouped = pd.DataFrame(train.groupby('location_id')['label'].agg('max')).reset_index()\ntest_grouped = pd.DataFrame(test.groupby('location_id')['event_id'].count()).reset_index()\ntest_grouped.columns = ['location_id', 'event_id_counts']\ndisplay(train_grouped.head(), test_grouped.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:52.713256Z","iopub.execute_input":"2025-02-17T10:09:52.713586Z","iopub.status.idle":"2025-02-17T10:09:52.799187Z","shell.execute_reply.started":"2025-02-17T10:09:52.713559Z","shell.execute_reply":"2025-02-17T10:09:52.798221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### COnfig","metadata":{}},{"cell_type":"code","source":"timm.list_models('eva*')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:52.800396Z","iopub.execute_input":"2025-02-17T10:09:52.800752Z","iopub.status.idle":"2025-02-17T10:09:52.807964Z","shell.execute_reply.started":"2025-02-17T10:09:52.800715Z","shell.execute_reply":"2025-02-17T10:09:52.806943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Config:\n    n_splits = 10\n    seed = 2024\n    image_path = \"/kaggle/input/final-deepmind-comp-dataset/final_deepmind_comp_dataset/Moisture Stress/\"\n    image_size = 224\n    img_extension = '.png'\n    model_name = \"eva02_tiny_patch14_224\"\n    batch_size = 32\n    epochs = 15\n    tta = 5\n    num_classes = 2\n\nlen(os.listdir(Config.image_path)), train_grouped.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:52.809324Z","iopub.execute_input":"2025-02-17T10:09:52.809645Z","iopub.status.idle":"2025-02-17T10:09:52.828020Z","shell.execute_reply.started":"2025-02-17T10:09:52.809610Z","shell.execute_reply":"2025-02-17T10:09:52.827233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits = Config.n_splits, shuffle=True, random_state = Config.seed)\ntrain_grouped['fold'] = -1\nfor fold, (_, val_idx) in enumerate(skf.split(train_grouped, train_grouped['label'])):\n    train_grouped.loc[val_idx, \"fold\"] = fold\n\ntrain_grouped['fold'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:52.828914Z","iopub.execute_input":"2025-02-17T10:09:52.829211Z","iopub.status.idle":"2025-02-17T10:09:52.850788Z","shell.execute_reply.started":"2025-02-17T10:09:52.829186Z","shell.execute_reply":"2025-02-17T10:09:52.850012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_grouped.label.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:52.851904Z","iopub.execute_input":"2025-02-17T10:09:52.852226Z","iopub.status.idle":"2025-02-17T10:09:52.859597Z","shell.execute_reply.started":"2025-02-17T10:09:52.852191Z","shell.execute_reply":"2025-02-17T10:09:52.858832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_grouped['image_path'] = Config.image_path + train_grouped['location_id'] + Config.img_extension\ntest_grouped['image_path'] = Config.image_path + test_grouped['location_id'] + Config.img_extension\ndisplay(train_grouped.head(), test_grouped.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:52.863253Z","iopub.execute_input":"2025-02-17T10:09:52.863544Z","iopub.status.idle":"2025-02-17T10:09:52.879466Z","shell.execute_reply.started":"2025-02-17T10:09:52.863506Z","shell.execute_reply":"2025-02-17T10:09:52.878228Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Albumentation Augmentations","metadata":{}},{"cell_type":"code","source":"class AlbumentationsTransform (RandTransform):\n    split_idx,order=None,2\n    def __init__(self, train_aug, valid_aug): store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        return PILImage.create(aug_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:52.880467Z","iopub.execute_input":"2025-02-17T10:09:52.880778Z","iopub.status.idle":"2025-02-17T10:09:52.886762Z","shell.execute_reply.started":"2025-02-17T10:09:52.880746Z","shell.execute_reply":"2025-02-17T10:09:52.885792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_train_aug(): return albumentations.Compose([\n            albumentations.Resize(Config.image_size, Config.image_size), #Extra tip, use size that's suitable for the efficentNetwork you are using.\n\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            \n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n              \n            ], p=1.)\n\n\n\ndef get_valid_aug(): return albumentations.Compose([\n            albumentations.Resize(Config.image_size, Config.image_size),\n            ], p=1.0)\n\nitem_tfms = AlbumentationsTransform(get_train_aug(), get_valid_aug())\nbatch_tfms = [Normalize.from_stats(*imagenet_stats)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:52.887975Z","iopub.execute_input":"2025-02-17T10:09:52.888309Z","iopub.status.idle":"2025-02-17T10:09:53.184779Z","shell.execute_reply.started":"2025-02-17T10:09:52.888244Z","shell.execute_reply":"2025-02-17T10:09:53.183867Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data Loaders","metadata":{}},{"cell_type":"code","source":"# to learn more about datablocks in fast you have to visit fastai.docs\ndef get_datablock(Train, fold=0, bs=32):\n    return DataBlock(blocks=(ImageBlock,CategoryBlock),\n                get_x=ColReader(\"image_path\"),\n                get_y=ColReader(['label']),\n                splitter=IndexSplitter(Train[Train.fold == fold].index),\n                item_tfms = item_tfms,\n                batch_tfms = batch_tfms).dataloaders(Train, bs=bs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:53.185962Z","iopub.execute_input":"2025-02-17T10:09:53.186329Z","iopub.status.idle":"2025-02-17T10:09:53.191532Z","shell.execute_reply.started":"2025-02-17T10:09:53.186272Z","shell.execute_reply":"2025-02-17T10:09:53.190500Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_datablock(train_grouped).show_batch(figsize=(12,12))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:53.192869Z","iopub.execute_input":"2025-02-17T10:09:53.193192Z","iopub.status.idle":"2025-02-17T10:09:55.826813Z","shell.execute_reply.started":"2025-02-17T10:09:53.193157Z","shell.execute_reply":"2025-02-17T10:09:55.825838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model + Metrics","metadata":{}},{"cell_type":"code","source":"roc = RocAucBinary()\nmetrics = [roc, accuracy]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:55.828116Z","iopub.execute_input":"2025-02-17T10:09:55.828504Z","iopub.status.idle":"2025-02-17T10:09:55.833371Z","shell.execute_reply.started":"2025-02-17T10:09:55.828463Z","shell.execute_reply":"2025-02-17T10:09:55.832418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize OOF predictions array with zeros\noof_preds = np.zeros((len(train_grouped), Config.num_classes))\nall_preds = []\nfor i in range(Config.n_splits):\n    # Get data for the current fold\n    print(f\"=======================================TRAINING FOLD: {i+1}================================================\")\n    dls = get_datablock(train_grouped, i, Config.batch_size)\n    learn = vision_learner(\n        dls, Config.model_name, \n        loss_func=CrossEntropyLossFlat(), \n        metrics=metrics, \n        cbs=[SaveModelCallback()]\n    )\n    \n    # Learning rate finder and fine-tune\n    _valley, _slide = learn.lr_find(suggest_funcs=(valley, slide))\n    learn.fine_tune(Config.epochs, _valley)\n    \n    # Generate OOF predictions for the validation set\n    val_idx = dls.valid.items.index\n    val_dl = learn.dls.valid\n    val_preds, _ = learn.tta(dl=val_dl, n=Config.tta)\n    \n    # Save OOF predictions for the current fold\n    oof_preds[val_idx] = val_preds.numpy()\n\n    # Generate test predictions\n    test_dl = learn.dls.test_dl(test_grouped)\n    preds, _ = learn.tta(dl=test_dl, n=Config.tta)\n    all_preds.append(preds)\n    \n    # Clean up to free memory\n    del learn\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# Add OOF predictions as a new column to the training dataset\ntrain_grouped['oof_preds'] = list(oof_preds)\ndisplay(train_grouped.head())\n\n\n# Display the updated DataFrame\ndisplay(train_grouped.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:09:55.834613Z","iopub.execute_input":"2025-02-17T10:09:55.835037Z","iopub.status.idle":"2025-02-17T10:29:19.720098Z","shell.execute_reply.started":"2025-02-17T10:09:55.834990Z","shell.execute_reply":"2025-02-17T10:29:19.719149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n\n# Extract the correct probability for each row in train_grouped\ntrain_grouped['flood_probability'] = train_grouped['oof_preds'].apply(\n    lambda preds: preds[1]  # Assuming `preds[1]` is the probability for the positive class (label = 1)\n    if len(preds) > 1 else preds[0]  # Safeguard if preds contains only one probability\n)\n\n# Calculate the ROC AUC score\nroc_score = roc_auc_score(train_grouped['label'], train_grouped['flood_probability'])\nprint(\"ROC AUC Score:\", roc_score)\n\n# Get the predicted class by choosing the class with the highest probability\ntrain_grouped['predicted_class'] = train_grouped['oof_preds'].apply(\n    lambda preds: 1 if preds[1] > preds[0] else 0  # If probability for class 1 is higher, predict class 1\n)\n\n# Calculate the accuracy score\naccuracy = accuracy_score(train_grouped['label'], train_grouped['predicted_class'])\nprint(\"Accuracy Score:\", accuracy)\n\n# Convert oof_preds (list of probabilities) into a NumPy array for log loss calculation\noof_probs = np.stack(train_grouped['oof_preds'].values)\n\n# Calculate the log loss\nlogloss = log_loss(train_grouped['label'], oof_probs)\nprint(\"Log Loss:\", logloss)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:29:57.298139Z","iopub.execute_input":"2025-02-17T10:29:57.299004Z","iopub.status.idle":"2025-02-17T10:29:57.317166Z","shell.execute_reply.started":"2025-02-17T10:29:57.298970Z","shell.execute_reply":"2025-02-17T10:29:57.316102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_grouped.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:30:02.980906Z","iopub.execute_input":"2025-02-17T10:30:02.981250Z","iopub.status.idle":"2025-02-17T10:30:02.993263Z","shell.execute_reply.started":"2025-02-17T10:30:02.981217Z","shell.execute_reply":"2025-02-17T10:30:02.992227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_grouped.to_csv(\"train_with_cv_results.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:30:03.200692Z","iopub.execute_input":"2025-02-17T10:30:03.201399Z","iopub.status.idle":"2025-02-17T10:30:03.263557Z","shell.execute_reply.started":"2025-02-17T10:30:03.201358Z","shell.execute_reply":"2025-02-17T10:30:03.262725Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### INFERENCE","metadata":{}},{"cell_type":"code","source":"# Convert the list of all_preds to a single NumPy array\n# Shape of all_preds: (n_splits, num_test_samples, num_classes)\nall_preds_array = np.array([pred.numpy() for pred in all_preds])\n\n# Compute the mean predictions across folds (axis=0)\nmean_test_preds = all_preds_array.mean(axis=0)\n\n# Extract the probability of the predicted class (highest probability)\n# For ROC AUC, we need the probabilities for the positive class (class 1)\n# Assuming the second column is for the positive class (class 1), adjust as needed\ntest_grouped['flood_probability'] = mean_test_preds[:, 1]  # Class 1 probability\n\n# Optionally, extract the predicted class (class with the highest probability)\ntest_grouped['predicted_class'] = mean_test_preds.argmax(axis=1)\n\n# Display the updated test DataFrame\ndisplay(test_grouped.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:30:03.542485Z","iopub.execute_input":"2025-02-17T10:30:03.542783Z","iopub.status.idle":"2025-02-17T10:30:03.558116Z","shell.execute_reply.started":"2025-02-17T10:30:03.542755Z","shell.execute_reply":"2025-02-17T10:30:03.557176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_grouped.to_csv(\"test_with_cv_results.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T10:30:03.710563Z","iopub.execute_input":"2025-02-17T10:30:03.710821Z","iopub.status.idle":"2025-02-17T10:30:03.718018Z","shell.execute_reply.started":"2025-02-17T10:30:03.710796Z","shell.execute_reply":"2025-02-17T10:30:03.717170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}